[2025-02-07T11:11:35.195+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: spark_minio_job_read.spark_minio_task manual__2025-02-07T10:37:49.361799+00:00 [queued]>
[2025-02-07T11:11:35.211+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: spark_minio_job_read.spark_minio_task manual__2025-02-07T10:37:49.361799+00:00 [queued]>
[2025-02-07T11:11:35.212+0000] {taskinstance.py:1308} INFO - Starting attempt 2 of 2
[2025-02-07T11:11:35.242+0000] {taskinstance.py:1327} INFO - Executing <Task(SparkSubmitOperator): spark_minio_task> on 2025-02-07 10:37:49.361799+00:00
[2025-02-07T11:11:35.254+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'spark_minio_job_read', 'spark_minio_task', 'manual__2025-02-07T10:37:49.361799+00:00', '--job-id', '127', '--raw', '--subdir', 'DAGS_FOLDER/spark_test_readingMinio_dag.py', '--cfg-path', '/tmp/tmp9p6dn0h5']
[2025-02-07T11:11:35.256+0000] {standard_task_runner.py:85} INFO - Job 127: Subtask spark_minio_task
[2025-02-07T11:11:35.256+0000] {standard_task_runner.py:57} INFO - Started process 87 to run task
[2025-02-07T11:11:35.393+0000] {task_command.py:410} INFO - Running <TaskInstance: spark_minio_job_read.spark_minio_task manual__2025-02-07T10:37:49.361799+00:00 [running]> on host 5ff0837888a1
[2025-02-07T11:11:35.966+0000] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='spark_minio_job_read' AIRFLOW_CTX_TASK_ID='spark_minio_task' AIRFLOW_CTX_EXECUTION_DATE='2025-02-07T10:37:49.361799+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-02-07T10:37:49.361799+00:00'
[2025-02-07T11:11:35.995+0000] {base.py:73} INFO - Using connection ID 'spark_default' for task execution.
[2025-02-07T11:11:36.002+0000] {spark_submit.py:340} INFO - Spark-Submit cmd: spark-submit --master spark://spark:7077 --conf spark.driver.extraClassPath=/opt/***/jars/* --conf spark.executor.extraClassPath=/opt/***/jars/* --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 --conf spark.hadoop.fs.s3a.access.key=minio --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.11.1026 --name arrow-spark --verbose /opt/***/dags/spark_test_readingMinio.py
[2025-02-07T11:11:41.128+0000] {spark_submit.py:491} INFO - Using properties file: null
[2025-02-07T11:11:41.553+0000] {spark_submit.py:491} INFO - Parsed arguments:
[2025-02-07T11:11:41.554+0000] {spark_submit.py:491} INFO - master                  spark://spark:7077
[2025-02-07T11:11:41.555+0000] {spark_submit.py:491} INFO - remote                  null
[2025-02-07T11:11:41.555+0000] {spark_submit.py:491} INFO - deployMode              null
[2025-02-07T11:11:41.556+0000] {spark_submit.py:491} INFO - executorMemory          null
[2025-02-07T11:11:41.557+0000] {spark_submit.py:491} INFO - executorCores           null
[2025-02-07T11:11:41.558+0000] {spark_submit.py:491} INFO - totalExecutorCores      null
[2025-02-07T11:11:41.559+0000] {spark_submit.py:491} INFO - propertiesFile          null
[2025-02-07T11:11:41.559+0000] {spark_submit.py:491} INFO - driverMemory            null
[2025-02-07T11:11:41.560+0000] {spark_submit.py:491} INFO - driverCores             null
[2025-02-07T11:11:41.560+0000] {spark_submit.py:491} INFO - driverExtraClassPath    /opt/***/jars/*
[2025-02-07T11:11:41.561+0000] {spark_submit.py:491} INFO - driverExtraLibraryPath  null
[2025-02-07T11:11:41.561+0000] {spark_submit.py:491} INFO - driverExtraJavaOptions  null
[2025-02-07T11:11:41.562+0000] {spark_submit.py:491} INFO - supervise               false
[2025-02-07T11:11:41.562+0000] {spark_submit.py:491} INFO - queue                   null
[2025-02-07T11:11:41.563+0000] {spark_submit.py:491} INFO - numExecutors            null
[2025-02-07T11:11:41.564+0000] {spark_submit.py:491} INFO - files                   null
[2025-02-07T11:11:41.564+0000] {spark_submit.py:491} INFO - pyFiles                 null
[2025-02-07T11:11:41.565+0000] {spark_submit.py:491} INFO - archives                null
[2025-02-07T11:11:41.566+0000] {spark_submit.py:491} INFO - mainClass               null
[2025-02-07T11:11:41.566+0000] {spark_submit.py:491} INFO - primaryResource         file:/opt/***/dags/spark_test_readingMinio.py
[2025-02-07T11:11:41.567+0000] {spark_submit.py:491} INFO - name                    arrow-spark
[2025-02-07T11:11:41.568+0000] {spark_submit.py:491} INFO - childArgs               []
[2025-02-07T11:11:41.569+0000] {spark_submit.py:491} INFO - jars                    null
[2025-02-07T11:11:41.570+0000] {spark_submit.py:491} INFO - packages                org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.11.1026
[2025-02-07T11:11:41.570+0000] {spark_submit.py:491} INFO - packagesExclusions      null
[2025-02-07T11:11:41.571+0000] {spark_submit.py:491} INFO - repositories            null
[2025-02-07T11:11:41.571+0000] {spark_submit.py:491} INFO - verbose                 true
[2025-02-07T11:11:41.572+0000] {spark_submit.py:491} INFO - 
[2025-02-07T11:11:41.572+0000] {spark_submit.py:491} INFO - Spark properties used, including those specified through
[2025-02-07T11:11:41.573+0000] {spark_submit.py:491} INFO - --conf and those from the properties file null:
[2025-02-07T11:11:41.574+0000] {spark_submit.py:491} INFO - (spark.driver.extraClassPath,/opt/***/jars/*)
[2025-02-07T11:11:41.575+0000] {spark_submit.py:491} INFO - (spark.executor.extraClassPath,/opt/***/jars/*)
[2025-02-07T11:11:41.576+0000] {spark_submit.py:491} INFO - (spark.hadoop.fs.s3a.access.key,*********(redacted))
[2025-02-07T11:11:41.576+0000] {spark_submit.py:491} INFO - (spark.hadoop.fs.s3a.aws.credentials.provider,org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider)
[2025-02-07T11:11:41.577+0000] {spark_submit.py:491} INFO - (spark.hadoop.fs.s3a.endpoint,http://minio:9000)
[2025-02-07T11:11:41.577+0000] {spark_submit.py:491} INFO - (spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)
[2025-02-07T11:11:41.578+0000] {spark_submit.py:491} INFO - (spark.hadoop.fs.s3a.path.style.access,true)
[2025-02-07T11:11:41.578+0000] {spark_submit.py:491} INFO - (spark.hadoop.fs.s3a.secret.key,*********(redacted))
[2025-02-07T11:11:41.579+0000] {spark_submit.py:491} INFO - 
[2025-02-07T11:11:41.579+0000] {spark_submit.py:491} INFO - 
[2025-02-07T11:11:42.128+0000] {spark_submit.py:491} INFO - :: loading settings :: url = jar:file:/opt/spark-3.4.0-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-02-07T11:11:42.438+0000] {spark_submit.py:491} INFO - Ivy Default Cache set to: /home/***/.ivy2/cache
[2025-02-07T11:11:42.438+0000] {spark_submit.py:491} INFO - The jars for the packages stored in: /home/***/.ivy2/jars
[2025-02-07T11:11:42.446+0000] {spark_submit.py:491} INFO - org.apache.hadoop#hadoop-aws added as a dependency
[2025-02-07T11:11:42.447+0000] {spark_submit.py:491} INFO - com.amazonaws#aws-java-sdk-bundle added as a dependency
[2025-02-07T11:11:42.448+0000] {spark_submit.py:491} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-687995ca-1b46-4d49-8162-ae36352453b0;1.0
[2025-02-07T11:11:42.448+0000] {spark_submit.py:491} INFO - confs: [default]
[2025-02-07T11:11:45.724+0000] {spark_submit.py:491} INFO - found org.apache.hadoop#hadoop-aws;3.3.4 in central
[2025-02-07T11:11:46.439+0000] {spark_submit.py:491} INFO - found com.amazonaws#aws-java-sdk-bundle;1.12.262 in central
[2025-02-07T11:11:47.685+0000] {spark_submit.py:491} INFO - found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central
[2025-02-07T11:11:47.721+0000] {spark_submit.py:491} INFO - downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar ...
[2025-02-07T11:11:47.830+0000] {spark_submit.py:491} INFO - [SUCCESSFUL ] org.apache.hadoop#hadoop-aws;3.3.4!hadoop-aws.jar (122ms)
[2025-02-07T11:11:47.845+0000] {spark_submit.py:491} INFO - downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar ...
[2025-02-07T11:12:01.296+0000] {spark_submit.py:491} INFO - [SUCCESSFUL ] com.amazonaws#aws-java-sdk-bundle;1.12.262!aws-java-sdk-bundle.jar (13464ms)
[2025-02-07T11:12:01.323+0000] {spark_submit.py:491} INFO - downloading https://repo1.maven.org/maven2/org/wildfly/openssl/wildfly-openssl/1.0.7.Final/wildfly-openssl-1.0.7.Final.jar ...
[2025-02-07T11:12:01.362+0000] {spark_submit.py:491} INFO - [SUCCESSFUL ] org.wildfly.openssl#wildfly-openssl;1.0.7.Final!wildfly-openssl.jar (58ms)
[2025-02-07T11:12:01.365+0000] {spark_submit.py:491} INFO - :: resolution report :: resolve 5256ms :: artifacts dl 13662ms
[2025-02-07T11:12:01.365+0000] {spark_submit.py:491} INFO - :: modules in use:
[2025-02-07T11:12:01.366+0000] {spark_submit.py:491} INFO - com.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]
[2025-02-07T11:12:01.366+0000] {spark_submit.py:491} INFO - org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]
[2025-02-07T11:12:01.367+0000] {spark_submit.py:491} INFO - org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]
[2025-02-07T11:12:01.368+0000] {spark_submit.py:491} INFO - :: evicted modules:
[2025-02-07T11:12:01.374+0000] {spark_submit.py:491} INFO - com.amazonaws#aws-java-sdk-bundle;1.11.1026 by [com.amazonaws#aws-java-sdk-bundle;1.12.262] in [default]
[2025-02-07T11:12:01.378+0000] {spark_submit.py:491} INFO - ---------------------------------------------------------------------
[2025-02-07T11:12:01.385+0000] {spark_submit.py:491} INFO - |                  |            modules            ||   artifacts   |
[2025-02-07T11:12:01.389+0000] {spark_submit.py:491} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-02-07T11:12:01.401+0000] {spark_submit.py:491} INFO - ---------------------------------------------------------------------
[2025-02-07T11:12:01.405+0000] {spark_submit.py:491} INFO - |      default     |   4   |   3   |   3   |   1   ||   3   |   3   |
[2025-02-07T11:12:01.409+0000] {spark_submit.py:491} INFO - ---------------------------------------------------------------------
[2025-02-07T11:12:01.454+0000] {spark_submit.py:491} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-687995ca-1b46-4d49-8162-ae36352453b0
[2025-02-07T11:12:01.455+0000] {spark_submit.py:491} INFO - confs: [default]
[2025-02-07T11:12:06.622+0000] {spark_submit.py:491} INFO - 3 artifacts copied, 0 already retrieved (275421kB/5166ms)
[2025-02-07T11:12:07.625+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-02-07T11:12:08.159+0000] {spark_submit.py:491} INFO - Main class:
[2025-02-07T11:12:08.160+0000] {spark_submit.py:491} INFO - org.apache.spark.deploy.PythonRunner
[2025-02-07T11:12:08.160+0000] {spark_submit.py:491} INFO - Arguments:
[2025-02-07T11:12:08.161+0000] {spark_submit.py:491} INFO - file:/opt/***/dags/spark_test_readingMinio.py
[2025-02-07T11:12:08.163+0000] {spark_submit.py:491} INFO - file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar,file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar
[2025-02-07T11:12:08.171+0000] {spark_submit.py:491} INFO - Spark config:
[2025-02-07T11:12:08.171+0000] {spark_submit.py:491} INFO - (spark.app.name,arrow-spark)
[2025-02-07T11:12:08.172+0000] {spark_submit.py:491} INFO - (spark.app.submitTime,1738926728109)
[2025-02-07T11:12:08.172+0000] {spark_submit.py:491} INFO - (spark.driver.extraClassPath,/opt/***/jars/*)
[2025-02-07T11:12:08.174+0000] {spark_submit.py:491} INFO - (spark.executor.extraClassPath,/opt/***/jars/*)
[2025-02-07T11:12:08.175+0000] {spark_submit.py:491} INFO - (spark.files,file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar,file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar)
[2025-02-07T11:12:08.176+0000] {spark_submit.py:491} INFO - (spark.hadoop.fs.s3a.access.key,*********(redacted))
[2025-02-07T11:12:08.177+0000] {spark_submit.py:491} INFO - (spark.hadoop.fs.s3a.aws.credentials.provider,org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider)
[2025-02-07T11:12:08.177+0000] {spark_submit.py:491} INFO - (spark.hadoop.fs.s3a.endpoint,http://minio:9000)
[2025-02-07T11:12:08.178+0000] {spark_submit.py:491} INFO - (spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)
[2025-02-07T11:12:08.178+0000] {spark_submit.py:491} INFO - (spark.hadoop.fs.s3a.path.style.access,true)
[2025-02-07T11:12:08.179+0000] {spark_submit.py:491} INFO - (spark.hadoop.fs.s3a.secret.key,*********(redacted))
[2025-02-07T11:12:08.180+0000] {spark_submit.py:491} INFO - (spark.jars,file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar,file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar)
[2025-02-07T11:12:08.181+0000] {spark_submit.py:491} INFO - (spark.master,spark://spark:7077)
[2025-02-07T11:12:08.183+0000] {spark_submit.py:491} INFO - (spark.repl.local.jars,file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar,file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar)
[2025-02-07T11:12:08.183+0000] {spark_submit.py:491} INFO - (spark.submit.deployMode,client)
[2025-02-07T11:12:08.184+0000] {spark_submit.py:491} INFO - (spark.submit.pyFiles,/home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,/home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar,/home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar)
[2025-02-07T11:12:08.185+0000] {spark_submit.py:491} INFO - Classpath elements:
[2025-02-07T11:12:08.185+0000] {spark_submit.py:491} INFO - file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar
[2025-02-07T11:12:08.186+0000] {spark_submit.py:491} INFO - file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar
[2025-02-07T11:12:08.186+0000] {spark_submit.py:491} INFO - file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar
[2025-02-07T11:12:08.187+0000] {spark_submit.py:491} INFO - 
[2025-02-07T11:12:08.188+0000] {spark_submit.py:491} INFO - 
[2025-02-07T11:12:11.456+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:11 INFO SparkContext: Running Spark version 3.4.0
[2025-02-07T11:12:11.602+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:11 INFO ResourceUtils: ==============================================================
[2025-02-07T11:12:11.604+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:11 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-02-07T11:12:11.609+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:11 INFO ResourceUtils: ==============================================================
[2025-02-07T11:12:11.610+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:11 INFO SparkContext: Submitted application: ReadFromMinIO
[2025-02-07T11:12:11.673+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:11 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-02-07T11:12:11.692+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:11 INFO ResourceProfile: Limiting resource is cpu
[2025-02-07T11:12:11.693+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:11 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-02-07T11:12:11.859+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:11 INFO SecurityManager: Changing view acls to: ***
[2025-02-07T11:12:11.860+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:11 INFO SecurityManager: Changing modify acls to: ***
[2025-02-07T11:12:11.862+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:11 INFO SecurityManager: Changing view acls groups to:
[2025-02-07T11:12:11.862+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:11 INFO SecurityManager: Changing modify acls groups to:
[2025-02-07T11:12:11.863+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ***; groups with view permissions: EMPTY; users with modify permissions: ***; groups with modify permissions: EMPTY
[2025-02-07T11:12:12.828+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:12 INFO Utils: Successfully started service 'sparkDriver' on port 38971.
[2025-02-07T11:12:12.995+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:12 INFO SparkEnv: Registering MapOutputTracker
[2025-02-07T11:12:13.112+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:13 INFO SparkEnv: Registering BlockManagerMaster
[2025-02-07T11:12:13.201+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:13 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-02-07T11:12:13.202+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:13 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-02-07T11:12:13.214+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:13 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-02-07T11:12:13.306+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:13 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fa9e8b53-aa8e-4a4a-8883-f4370c6e740f
[2025-02-07T11:12:13.368+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:13 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-02-07T11:12:13.464+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:13 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-02-07T11:12:13.794+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:13 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-02-07T11:12:13.951+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-02-07T11:12:14.009+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://5ff0837888a1:38971/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1738926731432
[2025-02-07T11:12:14.010+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar at spark://5ff0837888a1:38971/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1738926731432
[2025-02-07T11:12:14.011+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://5ff0837888a1:38971/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1738926731432
[2025-02-07T11:12:14.014+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:14 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://5ff0837888a1:38971/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1738926731432
[2025-02-07T11:12:14.016+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:14 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-5a42b676-5d6f-469e-85f6-02d088c38413/userFiles-eeaefe0a-f565-46ff-99d3-059b923172ee/org.apache.hadoop_hadoop-aws-3.3.4.jar
[2025-02-07T11:12:14.054+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:14 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar at spark://5ff0837888a1:38971/files/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1738926731432
[2025-02-07T11:12:14.054+0000] {spark_submit.py:491} INFO - 25/02/07 11:12:14 INFO Utils: Copying /home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar to /tmp/spark-5a42b676-5d6f-469e-85f6-02d088c38413/userFiles-eeaefe0a-f565-46ff-99d3-059b923172ee/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar
[2025-02-07T11:12:16.249+0000] {local_task_job_runner.py:291} WARNING - State of this instance has been externally set to failed. Terminating instance.
[2025-02-07T11:12:16.264+0000] {process_utils.py:131} INFO - Sending Signals.SIGTERM to group 87. PIDs of all processes in the group: [88, 146, 87]
[2025-02-07T11:12:16.265+0000] {process_utils.py:86} INFO - Sending the signal Signals.SIGTERM to group 87
[2025-02-07T11:12:16.270+0000] {taskinstance.py:1517} ERROR - Received SIGTERM. Terminating subprocesses.
[2025-02-07T11:12:16.275+0000] {spark_submit.py:618} INFO - Sending kill signal to spark-submit
[2025-02-07T11:12:16.504+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=87, status='terminated', exitcode=0, started='11:11:34') (87) terminated with exit code 0
[2025-02-07T11:12:16.507+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=88, status='terminated', started='11:11:35') (88) terminated with exit code None
[2025-02-07T11:12:16.509+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=146, status='terminated', started='11:12:07') (146) terminated with exit code None
