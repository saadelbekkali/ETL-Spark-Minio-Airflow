FROM bitnami/spark:3.4.0

USER root

# Install required system packages
RUN apt-get update && \
    apt-get install -y \
    python3.9 \
    python3.9-distutils \
    curl \
    wget \
    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1 \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Install pip for Python 3.9
RUN curl -sSL https://bootstrap.pypa.io/get-pip.py | python3.9

# Install required Python packages
RUN pip3 install \
    pandas \
    pyarrow \
    boto3

# Download necessary Hadoop AWS jars
RUN mkdir -p /opt/airflow/jars && \
    wget https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar -P /opt/airflow/jars/ && \
    wget https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.1026/aws-java-sdk-bundle-1.11.1026.jar -P /opt/airflow/jars/

ENV PYSPARK_PYTHON=python3.9
ENV PYSPARK_DRIVER_PYTHON=python3.9

# Set proper permissions for the jars directory
RUN chmod -R 777 /opt/airflow/jars

USER 1001